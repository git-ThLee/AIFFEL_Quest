{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "## 9-1 프로젝트: CAM을 만들고 평가해 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import PIL\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "print(cv2.__version__)\n",
    "print(PIL.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAM구현하기\n",
    "1. 이번 노드에 나왔던 CAM을 직접 구현해 봅시다. 예제 코드를 최대한 보지 말고, 설명과 이론을 보고 구현해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cam(model, item):\n",
    "    cam_image = None\n",
    "    # TODO: generate cam image\n",
    "    return cam_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 만든 함수로 CAM 이미지를 생성합시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_image = generate_cam(cam_model, item)\n",
    "plt.imshow(cam_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원본 이미지와 CAM 이미지를 입력으로 받고 두 개의 이미지의 투명도를 조정, 하나의 이미지에서 원본과 CAM을 겹쳐 보여주는 visualize_cam_on_image() 함수를 만들어보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_cam_on_image(image, cam_image):\n",
    "    # TODO: blend image\n",
    "    merged_image = None\n",
    "    return merged_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_cam_on_image() 함수 사용\n",
    "\n",
    "type(item['image'].numpy())\n",
    "\n",
    "origin_image = item['image'].numpy().astype(np.uint8)\n",
    "cam_image_3channel = np.stack([cam_image*255]*3, axis=-1).astype(np.uint8)\n",
    "\n",
    "blended_image = visualize_cam_on_image(cam_image_3channel, origin_image)\n",
    "plt.imshow(blended_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grad-CAM 구현하기\n",
    "1. 이번 노드에 나왔던 Grad-CAM을 직접 구현해 봅시다. 예제 코드를 최대한 보지 말고, 설명과 이론을 보고 구현해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_grad_cam(model, activation_layer, item):\n",
    "    grad_cam_image = None\n",
    "    # TODO: generate grad_cam_image\n",
    "\n",
    "    return grad_cam_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 만든 함수로 여러 레이어의 CAM 이미지를 뽑아서 직접 확인해 보세요.\n",
    "3. 위에서 만든 이미지 visualize_cam_on_image() 함수로 이미지를 시각화해 보세요.\n",
    "\n",
    "### 바운딩 박스 구하기\n",
    "1. 제시된 코드를 참고해, 직접 Grad-CAM으로 얻은 CAM을 통해서 바운딩 박스를 얻어보세요.\n",
    "2. 1)에서 얻은 바운딩 박스를 시각화해 보세요.\n",
    "\n",
    "### IOU 구하기\n",
    "1. 정답 바운딩 박스(ground truth) 와 예측값 바운딩 박스(prediction box) 두 가지를 이용해서 IoU를 계산하는 get_iou() 함수를 만들어 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou(gt_bbox, pred_bbox):\n",
    "    iou = None\n",
    "    # TODO: get iou between two bbox\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. CAM과 Grad-CAM으로 얻은 바운딩 박스와 정답 바운딩 박스와의 IoU를 각각 비교해 봅시다.\n",
    "\n",
    "<br><b>루브릭</b>\n",
    "<br>아래의 기준을 바탕으로 프로젝트를 평가합니다.\n",
    "<br>|평가문항|상세기준|\n",
    "<br>|1. CAM을 얻기 위한 기본모델의 구성과 학습이 정상 진행되었는가?|ResNet50 + GAP + DenseLayer 결합된 CAM 모델의 학습과정이 안정적으로 수렴하였다.|\n",
    "<br>|2. 분류근거를 설명 가능한 Class activation map을 얻을 수 있는가?|CAM 방식과 Grad-CAM 방식의 class activation map이 정상적으로 얻어지며, 시각화하였을 때 해당 object의 주요 특징 위치를 잘 반영한다.|\n",
    "<br>|3. 인식결과의 시각화 및 성능 분석을 적절히 수행하였는가?|CAM과 Grad-CAM 각각에 대해 원본이미지합성, 바운딩박스, IoU 계산 과정을 통해 CAM과 Grad-CAM의 object localization 성능이 비교분석되었다.|"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
